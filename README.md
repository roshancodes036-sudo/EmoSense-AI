# üß† EmoSense AI ‚Äî Intelligent Voice Sentiment Assistant

![EmoSense Banner](https://via.placeholder.com/1200x500.png?text=EmoSense+AI+Preview+Here)

> **"Your Voice, Your Emotions, Our Intelligence."**

[![Powered by Gemini](https://img.shields.io/badge/Powered%20by-Gemini%201.5%20Flash-4285F4?style=for-the-badge&logo=google)](https://deepmind.google/technologies/gemini/)
[![Built with Flutter](https://img.shields.io/badge/Built%20with-Flutter-02569B?style=for-the-badge&logo=flutter)](https://flutter.dev/)
[![Dart](https://img.shields.io/badge/Language-Dart-0175C2?style=for-the-badge&logo=dart)](https://dart.dev/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](./LICENSE)

---

## üöÄ What is EmoSense AI?

**EmoSense AI** is a next-generation mood detection application that bridges the gap between human speech and artificial emotional intelligence. 

Unlike traditional text-based sentiment tools, EmoSense listens to your **voice**, processes the audio in real-time, and uses **Google's Gemini 1.5 Flash** model to generate a comprehensive diagnostic report of your emotional state (Happy, Sad, Angry, Fear, etc.). All of this is presented in a stunning **Glassmorphism UI** inspired by futuristic interfaces.

---

## ‚ú® Key Features

| Feature | Description |
| :--- | :--- |
| **üéôÔ∏è Voice-First Interface** | Seamless speech-to-text conversion for natural interaction. |
| **üß† Advanced AI Core** | Powered by **Gemini 1.5 Flash** for deep semantic & emotional analysis. |
| **üé® Glassmorphism UI** | A visually striking, futuristic interface with dynamic animations. |
| **üìä Real-Time Diagnostics** | Visual breakdown of emotions (e.g., *Happy: 80%, Neutral: 20%*). |
| **üîí Privacy-First Architecture** | API keys and core logic are isolated from the codebase for maximum security. |

---

## üõ†Ô∏è Installation & Setup Guide (Critical)

> ‚ö†Ô∏è **Security Notice for Recruiters & Developers:** > To adhere to strict security best practices, the `lib/core/` directory (containing the API Key configuration) has been **git-ignored** and is NOT included in this repository. 
>
> **Please follow the steps below to reconstruct the environment and run the app.**

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone [https://github.com/roshancodes036-sudo/EmoSense-AI.git](https://github.com/roshancodes036-sudo/EmoSense-AI.git)
cd EmoSense-AI

2Ô∏è‚É£ Install Dependencies
flutter pub get

3Ô∏è‚É£ üîê Restore the Secret API Core
Since the core service is hidden, you must create it manually to connect to the AI.

Step A: Navigate to lib/ and create this folder structure:
lib/core/services/

Step B: Inside that folder, create a file named api_service.dart.

Step C: Paste the following code into that file. (You will need a free API Key from Google AI Studio)

import 'dart:convert';
import 'package:google_generative_ai/google_generative_ai.dart';

class ApiService {
  // üîë TODO: REPLACE THIS WITH YOUR GEMINI API KEY
  static const String _apiKey = "PASTE_YOUR_GEMINI_API_KEY_HERE";

  late final GenerativeModel _model;

  ApiService() {
    _model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: _apiKey,
    );
  }

  Future<Map<String, dynamic>> analyzeSentiment(String text) async {
    final prompt = '''
      Analyze the sentiment of the following text: "$text".
      Return the result strictly as a JSON object with this format:
      {
        "overall": {"Happy": 0, "Sad": 0, "Angry": 0, "Neutral": 0, "Fear": 0, "Surprise": 0},
        "details": "A one-line summary of why."
      }
      Do not include ```json or any markdown formatting. Just the raw JSON.
    ''';

    try {
      final content = [Content.text(prompt)];
      final response = await _model.generateContent(content);
      String? resultText = response.text;

      if (resultText != null) {
        resultText = resultText.replaceAll('```json', '').replaceAll('```', '').trim();
        return jsonDecode(resultText);
      } else {
        throw Exception("Empty response from AI");
      }
    } catch (e) {
      return {
        "overall": {"Happy": 0, "Sad": 0, "Angry": 0, "Neutral": 100},
        "details": "Error analyzing sentiment."
      };
    }
  }
}

4Ô∏è‚É£ Run the Application
flutter run

## üìÇ Professional Project Structure

We follow a clean, scalable architecture separating **UI (Views)** from **Logic (Core)**.

* üìÇ **lib/**
    * üîí **core/** ‚Äî *(Git-Ignored) Business Logic & Services*
        * üìÇ **services/**
            * üìÑ `api_service.dart` ‚Äî *The Brain (You must create this manually)*
    * üé® **views/** ‚Äî *UI Layer*
        * üìÇ **home/** ‚Äî *Main Voice Interface & Glass Panel*
        * üìÇ **splash/** ‚Äî *Cinematic Intro*
    * üß© **widgets/** ‚Äî *Reusable UI Components*
    * üöÄ `main.dart` ‚Äî *Application Entry Point*


## üõ†Ô∏è Tech Stack

* **Framework:** üê¶ [Flutter](https://flutter.dev) (Dart)
* **AI Model:** üß† [Google Gemini 1.5 Flash](https://deepmind.google/technologies/gemini/)
* **Speech Recognition:** üéôÔ∏è `speech_to_text`
* **Text-to-Speech:** üó£Ô∏è `flutter_tts`
* **State Management:** ‚ö° `setState` (Optimized for performance)
* **Architecture:** üõ°Ô∏è MVVM Style (Separation of Concerns)

## üë®‚Äçüíª Developed By

**Roshan**
*Passionate Flutter Developer & AI Innovator*

> *"Building the future of AI-powered interactions, one line of code at a time."*

[![GitHub](https://img.shields.io/badge/GitHub-roshancodes036--sudo-181717?style=for-the-badge&logo=github)](https://github.com/roshancodes036-sudo)

